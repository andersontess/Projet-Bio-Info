{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8abb7fb-910c-4590-925e-f83859f9a2a8",
   "metadata": {},
   "source": [
    "# **PROJET BIO-INFO : L'impact de la hausse des températures sur la puissance des ouragans**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611d8fec-2482-4e39-8e06-4f19f5ae15b0",
   "metadata": {},
   "source": [
    "# Membres du groupe:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81343e9a-588f-4126-876d-3dec7da5ca52",
   "metadata": {},
   "source": [
    "- Anderson TESS\n",
    "- Fiacre MITOKPE\n",
    "- Kenny RUFFINE\n",
    "- Gneneman Stéphane Jean-Baptiste KONÉ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc3e45c-b581-4999-b52f-53db54dd7fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns\n",
    "import folium\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import xarray as xr\n",
    "import tempfile\n",
    "import os\n",
    "!pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b97c1c-fffe-41e7-87e1-ee35210ab543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset sur les cyclones (certaines lignes ont plus de virgules, c'est pourquoi on \"skip\" dans les bad_lines)\n",
    "df2 = pd.read_csv(\"storms (1).csv\", sep=\",\", engine=\"python\", on_bad_lines=\"skip\")\n",
    "df2 = df2.drop(columns=[\"tropicalstorm_force_diameter\", \"hurricane_force_diameter\", \"pressure\"]) # colonnes qu'on veut supprimer\n",
    "df2 = df2[df2[\"status\"] == \"hurricane\"] # on regarde que les ouragans pour le moment\n",
    "\n",
    "\n",
    "\n",
    "# On garde que les moments min et max du vent pour chaque ouragan\n",
    "df2[\"wind\"] = pd.to_numeric(df2[\"wind\"], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e3382a-8b23-4000-9fde-76e9df2d2725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX WIND SPEEDS\n",
    "df2_max = df2.loc[df2.groupby([\"name\",\"year\"])[\"wind\"].idxmax()] # on groupe les ouragans par nom, puis on garde le moment ou le vent est au max\n",
    "\n",
    "# On trie le dataset par annee\n",
    "df2_max = df2_max.sort_values(by=\"year\", ascending=True) \n",
    "\n",
    "# on reset l'index pour faire plus propre\n",
    "df2_max = df2_max.reset_index(drop=True)\n",
    "\n",
    "# on affiche le dataset\n",
    "df2_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b840c764-5881-4cbb-bb2b-9aa780f491a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comptage du nombre d'ouragans par année\n",
    "hurricanes_per_year = df2_max[\"year\"].value_counts().sort_index()\n",
    "\n",
    "# Conversion des données en tableaux numpy\n",
    "x = hurricanes_per_year.index.values  # Années\n",
    "y = hurricanes_per_year.values        # Nombre d'ouragans\n",
    "\n",
    "# Ajustement d'une régression linéaire (droite de tendance)\n",
    "coeffs = np.polyfit(x, y, 1)  # Degré 1 = droite\n",
    "linear_trend = np.poly1d(coeffs)  # Crée une fonction polynomiale\n",
    "\n",
    "# Générer les valeurs prédites pour tracer la droite\n",
    "x_smooth = np.linspace(x.min(), x.max(), 300)  # Lissage\n",
    "y_smooth = linear_trend(x_smooth)\n",
    "\n",
    "# Tracé du graphique\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x, y, marker='o', linestyle='-', label=\"Ouragans par année\")\n",
    "\n",
    "# Ajout de la droite de tendance\n",
    "plt.plot(x_smooth, y_smooth, color='red', linestyle='--', label=\"Tendance (régression linéaire)\")\n",
    "\n",
    "# Ajout des labels et du titre\n",
    "plt.xlabel(\"Année\")\n",
    "plt.ylabel(\"Nombre d'ouragans\")\n",
    "plt.title(\"Nombre d'ouragans par année avec tendance linéaire\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Affichage du graphique\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167cf35f-c595-463c-af92-4a65b2d84227",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MIN WIND SPEEDS\n",
    "df2_min = df2.loc[df2.groupby([\"name\",\"year\"])[\"wind\"].idxmin()] # on groupe les ouragans par nom, puis on garde le moment ou le vent est au max\n",
    "\n",
    "# On trie le dataset par annee\n",
    "df2_min = df2_min.sort_values(by=\"year\", ascending=True) \n",
    "\n",
    "# on reset l'index pour faire plus propre\n",
    "df2_min = df2_min.reset_index(drop=True)\n",
    "\n",
    "# on affiche le dataset\n",
    "df2_min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69c1bb3-9378-45c6-b39d-ea9e8a7630f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_hurricane_year_by_index(df, index):\n",
    "    \"\"\"\n",
    "    retourne une seule ligne du dataset en fonction de l'indice donné en paramètre.\n",
    "\n",
    "    Paramètres:\n",
    "    df (DataFrame): dataset des ouragans.\n",
    "    index (int): indice de la ligne à recupérer.\n",
    "\n",
    "    Returns:\n",
    "    str : Une str Pandas contenant l'année, le mois, le jour, la latitude, la longitude et la catégorie, \n",
    "            ou un message d'erreur si l'index dépasse la taille du dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    required_columns = {\"year\"}\n",
    "\n",
    "    if not required_columns.issubset(df.columns):\n",
    "        return \"Error: The dataset does not contain all the required columns.\"\n",
    "\n",
    "    if index < 0 or index >= len(df):\n",
    "        return \"Error: Index out of range.\"\n",
    "\n",
    "    return int(df.loc[index, [\"year\"]])\n",
    "\n",
    "print(\"\\n\")\n",
    "index = 43 #1982 \n",
    "index2 = 102 #1995 \n",
    "index3 = 162 #2002\n",
    "index4 = 190 #2005 \n",
    "index5 = 228 #2010 \n",
    "index6 = 247 #2013 \n",
    "index7 = 300 #2020 \n",
    "hurricane_year1 = get_hurricane_year_by_index(df2_max, index)\n",
    "hurricane_year2 = get_hurricane_year_by_index(df2_max, index2)\n",
    "hurricane_year3 = get_hurricane_year_by_index(df2_max, index3)\n",
    "hurricane_year4 = get_hurricane_year_by_index(df2_max, index4)\n",
    "hurricane_year5 = get_hurricane_year_by_index(df2_max, index5)\n",
    "hurricane_year6 = get_hurricane_year_by_index(df2_max, index5)\n",
    "hurricane_year7 = get_hurricane_year_by_index(df2_max, index7)\n",
    "print(hurricane_year1)\n",
    "print(\"\\n\")\n",
    "print(hurricane_year2)\n",
    "print(\"\\n\")\n",
    "print(hurricane_year3)\n",
    "print(\"\\n\")\n",
    "print(hurricane_year4)\n",
    "print(\"\\n\")\n",
    "print(hurricane_year5)\n",
    "print(\"\\n\")\n",
    "print(hurricane_year6)\n",
    "print(\"\\n\")\n",
    "print(hurricane_year7)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe66758-0450-4416-97ef-b6cb16d5d555",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_hurricane_on_map_with_category(df):\n",
    "    \"\"\"\n",
    "    Affiche les positions des cyclones (latitude, longitude) sur une carte interactive avec une icône\n",
    "    correspondant à la catégorie de chaque ouragan.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): Le dataset des cyclones avec des colonnes 'lat', 'long' et 'category'.\n",
    "    \n",
    "    Returns:\n",
    "    folium.Map: Carte interactive affichant les cyclones avec des icônes basées sur leur catégorie.\n",
    "    \"\"\"\n",
    "    # Créer une carte centrée autour d'un point par défaut (ici, centre de l'océan Atlantique)\n",
    "    hurricane_map = folium.Map(location=[20, -50], zoom_start=3)\n",
    "\n",
    "    # Vérifier que les colonnes nécessaires existent dans le DataFrame\n",
    "    if 'lat' in df.columns and 'long' in df.columns and 'category' in df.columns:\n",
    "        # Dictionnaire pour associer une couleur à chaque catégorie\n",
    "        category_colors = {\n",
    "            1: 'blue',     # Catégorie 1 \n",
    "            2: 'green',    # Catégorie 2\n",
    "            3: 'yellow',   # Catégorie 3 \n",
    "            4: 'orange',   # Catégorie 4 \n",
    "            5: 'red'       # Catégorie 5  \n",
    "        }\n",
    "        \n",
    "        # Ajouter un marqueur pour chaque cyclone en fonction de la latitude et la longitude)\n",
    "        for index, row in df.iterrows():\n",
    "            category = row['category']\n",
    "            color = category_colors.get(category, 'gray')  # Utiliser 'gray' par défaut si la catégorie est inconnue\n",
    "            \n",
    "            folium.Marker(\n",
    "                location=[row['lat'], row['long']],\n",
    "                popup=f\"Name : {row['name']}, Year: {row['year']}, Month: {row['month']}, Day: {row['day']}, Category: {category}\",\n",
    "                icon=folium.Icon(color=color, icon='info-sign')\n",
    "            ).add_to(hurricane_map)\n",
    "    else:\n",
    "        print(\"Erreur : Les colonnes 'lat', 'long' et 'category' sont nécessaires dans le DataFrame.\")\n",
    "    \n",
    "    \n",
    "    return hurricane_map\n",
    "\n",
    "\n",
    "hurricane_map = plot_hurricane_on_map_with_category(df2_max)\n",
    "hurricane_map\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9c2fd5-e019-401b-b367-c4d2b33fe32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset sur les cyclones (certaines lignes ont plus de virgules, c'est pourquoi on \"skip\" dans les bad_lines)\n",
    "df2 = pd.read_csv(\"storms.csv\", sep=\",\", engine=\"python\", on_bad_lines=\"skip\")\n",
    "df2 = df2.drop(columns=[\"tropicalstorm_force_diameter\", \"hurricane_force_diameter\"]) # colonnes qu'on veut supprimer\n",
    "df2 = df2[df2[\"status\"] == \"hurricane\"] # on regarde que les ouragans pour le moment\n",
    "\n",
    "# On garde que les moments min et max du vent pour chaque ouragan\n",
    "df2[\"wind\"] = pd.to_numeric(df2[\"wind\"], errors=\"coerce\")\n",
    "\n",
    "# MAX WIND SPEEDS\n",
    "df2_max = df2.loc[df2.groupby(\"name\")[\"wind\"].idxmax()] # on groupe les ouragans par nom, puis on garde le moment ou le vent est au max\n",
    "\n",
    "# On trie le dataset par annee\n",
    "df2_max = df2_max.sort_values(by=\"year\", ascending=True) \n",
    "\n",
    "# on reset l'index pour faire plus propre\n",
    "df2_max = df2_max.reset_index(drop=True)\n",
    "\n",
    "# on affiche le dataset\n",
    "df2_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121985d5-bb1c-4391-9175-abb0c7f8b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MIN WIND SPEEDS\n",
    "df2_min = df2.loc[df2.groupby(\"name\")[\"wind\"].idxmin()] # on groupe les ouragans par nom, puis on garde le moment ou le vent est au max\n",
    "\n",
    "# On trie le dataset par annee\n",
    "df2_min = df2_min.sort_values(by=\"year\", ascending=True) \n",
    "\n",
    "# on reset l'index pour faire plus propre\n",
    "df2_min = df2_min.reset_index(drop=True)\n",
    "\n",
    "# on affiche le dataset\n",
    "df2_min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a30b044-ff2c-47aa-b53f-e2b68948f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Générer une plage de températures de la mer allant de 20°C à 30°C\n",
    "temperatures = np.linspace(20, 30, 500)\n",
    "\n",
    "# On considère que pour T < 26.5°C, le risque est faible (0)\n",
    "# et pour T >= 26.5°C, le risque devient élevé (1)\n",
    "risque = np.where(temperatures >= 26.5, 1, 0)\n",
    "\n",
    "# Création de la figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Tracé de la courbe du risque en fonction de la température\n",
    "plt.plot(temperatures, risque, label=\"Risque d'ouragan\", color='blue')\n",
    "\n",
    "# Ajout d'une ligne verticale pour marquer le seuil critique de 26.5°C\n",
    "plt.axvline(26.5, color='red', linestyle='--', label=\"Seuil critique: 26.5°C\")\n",
    "\n",
    "# Étiquettes et titre\n",
    "plt.xlabel(\"Température de la mer (°C)\")\n",
    "plt.ylabel(\"Risque d'ouragan (0 = faible, 1 = élevé)\")\n",
    "plt.title(\"Impact de la température de la mer sur le risque d'ouragan\")\n",
    "\n",
    "# Affichage de la légende et de la grille\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Affichage du graphique\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522b425d-bfd4-4eda-a494-f610543389ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def verify_files():\n",
    "    # Vérification du fichier CSV\n",
    "    csv_file = \"storms.csv\"\n",
    "    if os.path.exists(csv_file):\n",
    "        print(f\"Le fichier CSV '{csv_file}' a été trouvé.\")\n",
    "        # Affichage rapide des premières lignes\n",
    "        df = pd.read_csv(csv_file)\n",
    "        print(\"Aperçu du fichier CSV :\")\n",
    "        print(df.head())\n",
    "    else:\n",
    "        print(f\"Le fichier CSV '{csv_file}' n'a pas été trouvé.\")\n",
    "    \n",
    "    # Vérification du fichier NetCDF pour 1981\n",
    "    nc_file = \"sst.day.mean.2002.nc\"\n",
    "    if os.path.exists(nc_file):\n",
    "        print(f\"\\nLe fichier NetCDF '{nc_file}' a été trouvé.\")\n",
    "        ds = xr.open_dataset(nc_file)\n",
    "        print(\"Variables disponibles dans le fichier NetCDF :\", list(ds.data_vars))\n",
    "        print(\"Coordonnées disponibles :\", list(ds.coords))\n",
    "    else:\n",
    "        print(f\"Le fichier NetCDF '{nc_file}' n'a pas été trouvé.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    verify_files()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ac4850-8fae-4b43-a051-cb4d96dab1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_sst_for_year(year):\n",
    "    \"\"\"\n",
    "    Pour une année donnée, cette fonction lit le fichier CSV des tempêtes et le fichier\n",
    "    NetCDF des moyennes journalières de température de surface (SST) correspondant à cette année.\n",
    "    \n",
    "    Pour chaque événement de tempête de l'année (défini par la colonne 'year' du CSV),\n",
    "    elle crée une date en combinant les colonnes 'year', 'month' et 'day' et récupère la température de l'eau\n",
    "    (variable 'sst') à l'aide des coordonnées (lat, long) de l'événement.\n",
    "    \n",
    "    Paramètres:\n",
    "        year (int): L'année à analyser.\n",
    "        \n",
    "    Retour:\n",
    "        pd.DataFrame: Le DataFrame des tempêtes de l'année avec une colonne supplémentaire 'sst'\n",
    "                      indiquant la température de l'eau au moment et à l'emplacement de l'événement.\n",
    "    \"\"\"\n",
    "    # Lecture du fichier CSV des tempêtes\n",
    "    storms = pd.read_csv(\"storms.csv\")\n",
    "    \n",
    "    # Création d'une colonne datetime à partir des colonnes 'year', 'month', 'day'\n",
    "    # (le champ 'hour' est omis ici car le NetCDF contient des moyennes journalières)\n",
    "    storms[\"datetime\"] = pd.to_datetime(storms[[\"year\", \"month\", \"day\"]])\n",
    "    \n",
    "    # Filtrer les événements pour l'année spécifiée\n",
    "    storms_year = storms[storms[\"year\"] == year].copy()\n",
    "    \n",
    "    # Construction du nom du fichier NetCDF\n",
    "    nc_file = f\"sst.day.mean.{year}.nc\"\n",
    "    \n",
    "    # Ouverture du fichier NetCDF avec xarray\n",
    "    ds = xr.open_dataset(nc_file)\n",
    "    \n",
    "    # Liste pour stocker les valeurs de SST pour chaque événement\n",
    "    sst_values = []\n",
    "    \n",
    "    # Pour chaque événement, récupération de la température (variable 'sst') \n",
    "    # en utilisant la méthode 'nearest' pour sélectionner la valeur la plus proche selon la date et les coordonnées\n",
    "    for idx, row in storms_year.iterrows():\n",
    "        event_date = row[\"datetime\"]\n",
    "        event_lat = row[\"lat\"]\n",
    "        event_lon = row[\"long\"]  # la colonne s'appelle 'long' dans le CSV et 'lon' dans le NetCDF\n",
    "        try:\n",
    "            sst_val = ds[\"sst\"].sel(time=event_date, lat=event_lat, lon=event_lon, method=\"nearest\").values.item()\n",
    "        except Exception as e:\n",
    "            # Si la sélection échoue (par exemple, si l'événement est en dehors du domaine du NetCDF), retourner None\n",
    "            sst_val = None\n",
    "        sst_values.append(sst_val)\n",
    "    \n",
    "    # Ajout de la colonne 'sst' dans le DataFrame des tempêtes\n",
    "    storms_year[\"sst\"] = sst_values\n",
    "    \n",
    "    return storms_year\n",
    "\n",
    "# Exemple d'utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    annee = 1981  # Remplacer par l'année souhaitée\n",
    "    result_df = get_sst_for_year(annee)\n",
    "    print(result_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ca73f8-3455-46e9-9dbe-63575b8a901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sst_for_year(year):\n",
    "    \"\"\"\n",
    "    Pour une année donnée, cette fonction lit le fichier CSV des tempêtes et le fichier\n",
    "    NetCDF des moyennes journalières de température de surface (SST) correspondant à cette année.\n",
    "    \n",
    "    Pour chaque événement de tempête de l'année (défini par la colonne 'year' du CSV),\n",
    "    elle crée une date en combinant les colonnes 'year', 'month' et 'day' et récupère la température de l'eau\n",
    "    (variable 'sst') en utilisant les coordonnées (lat, long) de l'événement.\n",
    "    \n",
    "    Paramètres:\n",
    "        year (int): L'année à analyser.\n",
    "        \n",
    "    Retour:\n",
    "        pd.DataFrame: Le DataFrame des tempêtes de l'année avec une colonne supplémentaire 'sst'\n",
    "                      indiquant la température de l'eau au moment et à l'emplacement de l'événement.\n",
    "    \"\"\"\n",
    "    # Lecture du fichier CSV des tempêtes\n",
    "    storms = pd.read_csv(\"storms.csv\")\n",
    "    \n",
    "    # Création d'une colonne datetime à partir des colonnes 'year', 'month', 'day'\n",
    "    storms[\"datetime\"] = pd.to_datetime(storms[[\"year\", \"month\", \"day\"]])\n",
    "    \n",
    "    # Filtrer les événements pour l'année spécifiée\n",
    "    storms_year = storms[storms[\"year\"] == year].copy()\n",
    "    \n",
    "    # Construction du nom du fichier NetCDF\n",
    "    nc_file = f\"sst.day.mean.{year}.nc\"\n",
    "    \n",
    "    # Ouverture du fichier NetCDF avec xarray\n",
    "    ds = xr.open_dataset(nc_file)\n",
    "    \n",
    "    # Liste pour stocker les valeurs de SST pour chaque événement\n",
    "    sst_values = []\n",
    "    \n",
    "    # Pour chaque événement, récupération de la température (variable 'sst')\n",
    "    # en utilisant la méthode 'nearest' pour sélectionner la valeur la plus proche selon la date et les coordonnées\n",
    "    for idx, row in storms_year.iterrows():\n",
    "        event_date = row[\"datetime\"]\n",
    "        event_lat = row[\"lat\"]\n",
    "        event_lon = row[\"long\"]  # dans le CSV la colonne s'appelle 'long' et dans le NetCDF 'lon'\n",
    "        try:\n",
    "            sst_val = ds[\"sst\"].sel(time=event_date, lat=event_lat, lon=event_lon, method=\"nearest\").values.item()\n",
    "        except Exception as e:\n",
    "            sst_val = None\n",
    "        sst_values.append(sst_val)\n",
    "    \n",
    "    # Ajout de la colonne 'sst' dans le DataFrame\n",
    "    storms_year[\"sst\"] = sst_values\n",
    "    \n",
    "    return storms_year\n",
    "\n",
    "def plot_sst_for_year(year):\n",
    "    \"\"\"\n",
    "    Pour une année donnée, cette fonction récupère les données de tempête avec leur SST associée\n",
    "    et affiche un graphique avec la date sur l'axe x et la température (SST) sur l'axe y.\n",
    "    \"\"\"\n",
    "    # Récupération des données\n",
    "    df = get_sst_for_year(year)\n",
    "    \n",
    "    # On élimine les événements sans donnée SST\n",
    "    df = df[df['sst'].notnull()]\n",
    "    \n",
    "    # Création du graphique\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(df['datetime'], df['sst'], color='blue', label='Température SST')\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Température de surface de la mer (SST)\")\n",
    "    plt.title(f\"Température de surface de la mer lors des ouragans en {year}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Exemple d'utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    annee =hurricane_year3  # Remplacer par l'année souhaitée\n",
    "    plot_sst_for_year(annee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a406e9cf-a9cd-4a45-9056-d0ce0b6dc442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
